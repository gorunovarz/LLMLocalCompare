{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbff0206-338d-4dee-983b-c6592c0797d8",
   "metadata": {},
   "source": [
    "### Генерация ответов LLM, запись в .csv файл"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13552af8-7776-442a-9c74-bc1076d4f64e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134a964b-7618-4b83-a60e-fb4876ec40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from statistics import mean\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203e65bf-db43-41e2-b6c6-199e083754a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LLM model, choose from ollama.com\n",
    "# Ollama model chould be installed beforehand \n",
    "LLM_model = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c23930-ef03-4a3f-bda3-584765a8eb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: /home/alex/Desktop/LLMLocalCompare/Test Data/mike_and_classical_music\n",
      "Results directory: /home/alex/Desktop/LLMLocalCompare/responses\n"
     ]
    }
   ],
   "source": [
    "# Set path to answers data directory\n",
    "p_dataset = (Path('..')/\"Test Data\"/\"mike_and_classical_music\").resolve().absolute()\n",
    "print(f\"Dataset directory: {p_dataset}\")\n",
    "\n",
    "# Set path to results directory\n",
    "p_results = (Path('..')/\"responses\").resolve().absolute()\n",
    "print(f\"Results directory: {p_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e579da04-3942-470e-a332-0fbd971f60a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key question: Does Mike like classical music because it helps him relax or calm down?\n",
      "Correct answer: Mike likes listening to classical music because it is calming.\n"
     ]
    }
   ],
   "source": [
    "# Function to load text from .txt file\n",
    "def load_from_txt(path):\n",
    "    with open(path) as f:\n",
    "        texttt = f.read().replace(\"\\n\", \"\")\n",
    "    return texttt\n",
    "\n",
    "# Load test question and correct answer from answers data directory\n",
    "test_question = load_from_txt(p_dataset/\"test_question.txt\")\n",
    "key_question = load_from_txt(p_dataset/\"key_question.txt\")\n",
    "correct_answer = load_from_txt(p_dataset/\"correct_answer.txt\")\n",
    "\n",
    "print(f\"Key question: {key_question}\")\n",
    "print(f\"Correct answer: {correct_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac03dd1a-c397-42b3-95ca-2329d3f1a7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     N  Correctness                                             Answer\n",
      "0    1         True  Mike likes listening to classical music, it is...\n",
      "1    2         True  Mike likes listening to classical music, it is...\n",
      "2    3         True                    Classical music calms him down.\n",
      "3    4         True  When Mike listens to classical music, he feels...\n",
      "4    5         True                 Mike is calmed by classical music.\n",
      "..  ..          ...                                                ...\n",
      "67  68        False  Mike likes the sounds of classical music, they...\n",
      "68  69        False  Mike likes waking up to the sounds of classica...\n",
      "69  70        False  Mike likes classical music because he composes...\n",
      "70  71        False  Mike likes classical music because it is diffi...\n",
      "71  72        False                             Mike likes its rhythm.\n",
      "\n",
      "[72 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load student's answers from .csv file from answers data directory\n",
    "answers_data_csv = pd.read_csv(p_dataset/\"answers_data.csv\", sep=':', lineterminator='\\n')\n",
    "print(answers_data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1be3aa6-0541-4588-9db1-6666eff9faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_data_N = answers_data_csv[\"N\"]\n",
    "answers_data_correctness = answers_data_csv[\"Correctness\"]\n",
    "answers_data_answer = answers_data_csv[\"Answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c66f577a-830a-4ce6-831c-33df291a3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results .csv file and create header for data colomns\n",
    "results_filename = f\"v7_res_{time.time()}.csv\"\n",
    "with open(p_results/results_filename, 'w') as file:\n",
    "    file.write(\"Ans #:Ans correct:Temperature:LLM correct:Run time:LLM response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a353d0-2d6d-4a23-a7d7-8e6d5cc61efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove <think>...</think> from the LLM response\n",
    "# Does nothing if \"</think>\" is not found\n",
    "def remove_thinking(response):\n",
    "    think_token = r\"</think>\"\n",
    "    think_token_pos = response.find(think_token)\n",
    "    if think_token_pos == -1:\n",
    "        return response\n",
    "    response_without_thinking = response[think_token_pos+len(think_token)+2:]\n",
    "    return response_without_thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2bf488-e4bb-442d-9e45-1e2904a4fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike likes listening to classical music, it is calming. Based on the previous sentence, answer the question: Does Mike like classical music because it helps him relax or calm down? Answer only yes or no. If the answer is incorrect, just answer \"no\".\n"
     ]
    }
   ],
   "source": [
    "# Function to create a prompt from a key_question and a student_answer\n",
    "def prompt_func2(key_question, student_answer):\n",
    "    return student_answer + \\\n",
    "    \" Based on the previous sentence, answer the question: \" + \\\n",
    "    key_question + \\\n",
    "    \" Answer only yes or no.\" + \\\n",
    "    \" If the answer is incorrect, just answer \\\"no\\\".\"\n",
    "\n",
    "print(prompt_func2(key_question, answers_data_answer[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e29c6-55b6-42c5-85e5-a9cbb85f68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "# answers_range = [0, 56]\n",
    "# temperatures = [0.0, 0.1]\n",
    "# epochs = 2\n",
    "\n",
    "# Real parameters\n",
    "answers_range = list(range(len(answers_data_N)))\n",
    "temperatures = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "epochs = 20\n",
    "\n",
    "# Nested loops to generate LLM responses, mark them as correct/incorrect and save to .csv file\n",
    "# for every student's answer, for every temperature, for every epoch\n",
    "for answer_N in answers_range:\n",
    "    prompt = prompt_func2(key_question, answers_data_answer[answer_N])\n",
    "    answer_data_number = answers_data_N[answer_N]\n",
    "    answer_correctness = answers_data_correctness[answer_N]\n",
    "    for (j, temp) in enumerate(temperatures):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Running answer #{answer_N}; Running temp #{j}; Running epoch #{epoch};      \", end=\"\\r\")\n",
    "            time_start = time.time()\n",
    "            gen = ollama.generate(model=LLM_model, prompt=prompt, options={\"temperature\":temp})\n",
    "            time_end = time.time()\n",
    "            run_time = time_end - time_start\n",
    "            rs = gen.response\n",
    "            response_without_thinking = remove_thinking(rs)\n",
    "            LLM_correct = ((\"yes\" in response_without_thinking.lower()) == answer_correctness)\n",
    "            with open(p_results/results_filename, 'a') as file:\n",
    "                rs_safe_for_csv = rs.replace(\":\",\"\").replace(\"\\n\",\"\")\n",
    "                to_write = f\"\\n{answer_data_number}:{answer_correctness}:{temp}:{LLM_correct}:{run_time}:{rs_safe_for_csv}\"\n",
    "                try: \n",
    "                    file.write(to_write) # Can throw an unexpected error, if response contains some charecters\n",
    "                except:\n",
    "                    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd68d5-93f9-48c8-82d2-b7f2adfa82ef",
   "metadata": {},
   "source": [
    "Далее ответы LLM, сохраненные в .csv файле, обрабатываются в `final-csv_results_processing.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5733cf7-b94a-417f-aa9e-2719947f0357",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
